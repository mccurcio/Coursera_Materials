---
title: "cleaning_data_wk1_quiz"
author: "MCCurcio"
date: "12/17/2020"
output: html_document
---

##############################################################################
# Question 1
The American Community Survey distributes downloadable data about United States communities. Download the 2006 microdata survey about housing for the state of Idaho using download.file() from here: 

`https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv`

and load the data into R. The code book, describing the variable names is here:

`https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FPUMSDataDict06.pdf` 

How many properties are worth $1,000,000 or more?

```{r message=FALSE, warning=FALSE}
setwd("~/Dropbox/R_exercises/Coursera/Data_cleaning/week1")
library(readr)
ss06hid <- read_csv("getdata_data_ss06hid.csv")
dim(ss06hid)
```

```{r}
library("data.table")
property_vals <- ss06hid[37]
head(property_vals)
```

```{r}
million_plus <- subset(property_vals, property_vals$VAL == 24)
million_plus
nrow(million_plus) 
```

##############################################################################
# Question 2
Use the data you loaded from Question 1. 
Consider the variable FES in the code book. 
Which of the "tidy data" principles does this variable violate? 

[]Tidy data has variable values that are internally consistent. 
[]Each variable in a tidy data set has been transformed to be interpretable. 
[]Numeric values in tidy data can not represent categories. 
[X]Tidy data has one variable per column. 

```{r}
unique(ss06hid$FES)
sort(unique(ss06hid$FES))
```


##############################################################################
# Question 3
Download the Excel spreadsheet on Natural Gas Aquisition Program here: 

https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FDATA.gov_NGAP.xlsx 

Read rows 18-23 and columns 7-15 into R and assign the result to a variable called:

```{r message=FALSE, warning=FALSE}
library(readxl)
data_gov_ngap <- read_excel("getdata_data_DATA.gov_NGAP.xlsx")
#View(data_gov_ngap)
```

```{r}
dat <- data_gov_ngap[18:23, 7:15]
#View(dat)

# Change colnames of all columns
colnames(dat) <- c("Zip", "CuCurrent", "PaCurrent",
                   "PoCurrent", "Contact", "Ext",
                   "Fax", "email", "Status")
View(dat)

dat$Zip <- as.numeric(dat$Zip)
class(dat$Zip)
```

```{r}
dat$Ext <- as.numeric(dat$Ext)
class(dat$Ext)
```

```{r}
sum(dat$Zip*dat$Ext, na.rm = T)
```

##############################################################################
# Question 4.
Read the XML data on Baltimore restaurants from here:

https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml 

How many restaurants have zipcode 21231? 


```{r}
fileUrl <- "http://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
doc <- xmlTreeParse(fileUrl, useInternal=TRUE)
rootNode <- xmlRoot(doc)
sum(xpathSApply(rootNode, "//zipcode", xmlValue)==21231)
```

??
```{r}
# file_url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
# download.file(file_url, 
#               destfile = "restaurants.xml",
#               method = "curl")
```

??
```{r}
library("RCurl")
library("XML")
fileURL <- "http://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
data.unparsed <- getURL(fileURL)
data <- xmlTreeParse(data.unparsed, useInternal = TRUE)
rootNode <- xmlRoot(data)
sum(xpathSApply(rootNode, "//zipcode", xmlValue)==21231)
```



```{r}
### reading xml in to R to DF

library("XML")

url <- "http://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"

download.file(url, "restaurants.xml")

doc <- xmlTreeParse("restaurants.xml", useInternalNodes=TRUE)
rootNode = xmlRoot(doc)
xmlName(rootNode)

sum(xpathSApply(rootNode, "//zipcode", xmlValue)==21231)
```



##########################################################################
# Question 5. 
The American Community Survey distributes downloadable data about United States communities. Download the 2006 microdata survey about housing for the state of Idaho using download.file() from here: 

https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv

using the fread() command load the data into an R object

`DT`

The following are ways to calculate the average value of the variable

`pwgtp15`

broken down by sex. Using the **data.table package**, which will deliver the fastest user time? 


[]mean(DT$pwgtp15,by=DT$SEX)

[]mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15)

[]rowMeans(DT)[DT$SEX==1]; rowMeans(DT)[DT$SEX==2]

[]tapply(DT$pwgtp15,DT$SEX,mean)

[]DT[,mean(pwgtp15),by=SEX]

[]sapply(split(DT$pwgtp15,DT$SEX),mean)

```{r}
library("curl")
library("data.table")
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv"
download.file(fileUrl, destfile="ss06pid.csv", method="curl")
DT <- fread("ss06pid.csv")

file.info("ss06pid.csv")$size
```

```{r}
system.time(DT[,mean(pwgtp15),by=SEX])
```

```{r}
system.time(mean(DT[DT$SEX==1,]$pwgtp15))+system.time(mean(DT[DT$SEX==2,]$pwgtp15))
```

```{r}
system.time(sapply(split(DT$pwgtp15,DT$SEX),mean))
```

```{r}
system.time(mean(DT$pwgtp15,by=DT$SEX))
```

```{r}
system.time(tapply(DT$pwgtp15,DT$SEX,mean))
```

```{r}
system.time(sapply(split(DT$pwgtp15,DT$SEX),mean))
```



















